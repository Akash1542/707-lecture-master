{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMezxvu6h1Kxsqglt2Pbq4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akash1542/707-lecture-master/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KljTsKTgyPfR"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to preprocess data.\n",
        "def preprocess(X):\n",
        "# Handling missing values (fill with 0)\n",
        "    X.fillna(0, inplace=True)\n",
        "\n",
        "# Standardizing features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled"
      ],
      "metadata": {
        "id": "aVu3l_E7jP9C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to evaluate model using cross-validation and F1-score.\n",
        "def evaluate_model(model, X, y):\n",
        "    f1_scores = cross_val_score(model, X, y, cv=5, scoring='f1')\n",
        "    return f1_scores.mean()"
      ],
      "metadata": {
        "id": "e6BI9_dyhAgl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating dataset A.\n",
        "np.random.seed(42)\n",
        "X_A, y_A = make_classification(n_samples=1000, n_features=20, n_classes=2, weights=[0.5, 0.5], class_sep=0.1, random_state=42)\n",
        "\n",
        "# Generate dataset B\n",
        "X_B, y_B = make_classification(n_samples=1000, n_features=20, n_classes=2, weights=[0.1, 0.9], class_sep=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "cb5lH1VOjsVz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting datasets to pandas DataFrames.\n",
        "data_A = pd.DataFrame(X_A, columns=[f'feature_{i}' for i in range(X_A.shape[1])])\n",
        "data_A['target'] = y_A\n",
        "\n",
        "data_B = pd.DataFrame(X_B, columns=[f'feature_{i}' for i in range(X_B.shape[1])])\n",
        "data_B['target'] = y_B"
      ],
      "metadata": {
        "id": "NoplvndXjwYt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data for both datasets.\n",
        "X_A_scaled = preprocess(data_A.drop('target', axis=1))\n",
        "y_A = data_A['target']\n",
        "\n",
        "X_B_scaled = preprocess(data_B.drop('target', axis=1))\n",
        "y_B = data_B['target']"
      ],
      "metadata": {
        "id": "7XIG-3LIj0Q-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing logistic regression and decision tree classifiers.\n",
        "lr_model = LogisticRegression()\n",
        "dt_model = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "_dpXKkJgj2v6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating models on dataset A.\n",
        "f1_lr_A = evaluate_model(lr_model, X_A_scaled, y_A)\n",
        "f1_dt_A = evaluate_model(dt_model, X_A_scaled, y_A)\n",
        "\n",
        "# Evaluating models on dataset B.\n",
        "f1_lr_B = evaluate_model(lr_model, X_B_scaled, y_B)\n",
        "f1_dt_B = evaluate_model(dt_model, X_B_scaled, y_B)"
      ],
      "metadata": {
        "id": "ANf-iArjj5Ho"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating performance difference.\n",
        "print(\"Dataset A \\n Logistic Regression:\", f1_lr_A)\n",
        "print(\"Decision Tree Classifier:\", f1_dt_A)\n",
        "print(\"Dataset B \\n Logistic Regression:\", f1_lr_B)\n",
        "print(\"Decision Tree Classifier:\", f1_dt_B)\n",
        "print(\"Dataset A Performance Difference between both the models:\", abs(f1_lr_A - f1_dt_A))\n",
        "print(\"Dataset B Performance Difference between both the models:\", abs(f1_lr_B - f1_dt_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYxjCgeGj7nv",
        "outputId": "f622e765-e162-41c1-fa5e-7b94ef251df5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset A \n",
            " Logistic Regression: 0.5311199388846448\n",
            "Decision Tree Classifier: 0.6554729353772546\n",
            "Dataset B \n",
            " Logistic Regression: 0.9395444877589844\n",
            "Decision Tree Classifier: 0.9103548718922598\n",
            "Dataset A Performance Difference between both the models: 0.12435299649260978\n",
            "Dataset B Performance Difference between both the models: 0.029189615866724528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving datasets to CSV files.\n",
        "data_A.to_csv('data_A.csv', index=False)\n",
        "data_B.to_csv('data_B.csv', index=False)"
      ],
      "metadata": {
        "id": "FV4g0rJDj-SJ"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}